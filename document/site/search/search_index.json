{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"src/RL/gaussian-splatting/gaussian-splatting/","title":"3D Gaussian Splatting","text":"<p>3DGS<sup>[1]</sup> \u662f\u57fa\u4e8e Splatting \u548c\u673a\u5668\u5b66\u4e60\u7684\u4e09\u7ef4\u91cd\u5efa\u65b9\u6cd5\u3002\u5176\u4e2d Splat \u662f\u62df\u58f0\u8bcd\uff0c\u610f\u4e3a\u201c\u556a\u53fd\u4e00\u58f0\u201d\uff1a\u6211\u4eec\u53ef\u4ee5\u60f3\u8c61\u4e09\u7ef4\u573a\u666f\u91cd\u5efa\u7684\u8f93\u5165\u662f\u4e00\u4e9b\u96ea\u7403\uff0c\u56fe\u7247\u662f\u4e00\u9762\u7816\u5899\uff0c\u56fe\u50cf\u751f\u6210\u8fc7\u7a0b\u5c31\u662f\u5411\u5899\u9762\u6254\u96ea\u7403\u7684\u8fc7\u7a0b\uff1b\u6bcf\u6254\u4e00\u4e2a\u96ea\u7403\uff0c\u5899\u9762\u4e0a\u4f1a\u7559\u6709\u5370\u8bb0\uff0c\u5e76\u4f34\u6709\u556a\u53fd\u4e00\u58f0\uff0c\u6240\u4ee5\u8fd9\u4e2a\u7b97\u6cd5\u4e5f\u88ab\u79f0\u4e3a\u629b\u96ea\u7403\u6cd5\uff0c\u7ffb\u8bd1\u6210\u201c\u55b7\u6e85\u201d\u4e5f\u5f88\u6709\u7075\u6027\u3002\u7b80\u5355\u6765\u8bf4\uff0csplatting \u7684\u6838\u5fc3\u6709\u4e09\u6b65\uff1a\u4e00\u662f\u9009\u62e9\u201c\u96ea\u7403\u201d\uff0c\u4e5f\u5c31\u662f\u8bf4\u6211\u8981\u5c06\u5b83\u634f\u6210\u4e00\u4e2a\u4ec0\u4e48\u5f62\u72b6\u7684\u96ea\u7403\uff1b\u4e8c\u662f\u53bb\u629b\u63b7\u96ea\u7403\uff0c\u5c06\u9ad8\u65af\u692d\u7403\u4ece 3D \u6295\u5f71\u5230 2D\uff0c\u5f97\u5230\u5f88\u591a\u4e2a\u5370\u8bb0\uff1b\u4e09\u662f\u5408\u6210\u8fd9\u4e9b\u5370\u8bb0\u4ee5\u5f62\u6210\u6700\u540e\u7684\u56fe\u50cf<sup>[2]</sup>\u3002</p>"},{"location":"src/RL/gaussian-splatting/gaussian-splatting/#\u634f\u96ea\u7403\u7528\u534f\u65b9\u5dee\u63a7\u5236\u692d\u7403\u5f62\u72b6","title":"\u634f\u96ea\u7403\uff1a\u7528\u534f\u65b9\u5dee\u63a7\u5236\u692d\u7403\u5f62\u72b6","text":"<p>3DGS \u7684\u8f93\u5165\u662f SfM \u5f97\u5230\u7684\u7a00\u758f\u70b9\u4e91\uff0c\u800c\u7531\u4e8e\u70b9\u662f\u6ca1\u6709\u4f53\u79ef\u7684\uff0c\u6211\u4eec\u9996\u5148\u9700\u8981\u5c06\u70b9\u81a8\u80c0\u6210\u6b63\u65b9\u4f53\u3001\u7403\u4f53\u6216\u8005\u5176\u4ed6\u57fa\u7840\u7684\u4e09\u7ef4\u51e0\u4f55\u5f62\u72b6\u3002\u4e4b\u6240\u4ee5\u9009\u62e9\u9ad8\u65af\u5206\u5e03\u4f5c\u4e3a\u692d\u7403\uff0c\u5219\u662f\u56e0\u4e3a\u5b83\u826f\u597d\u7684\u6570\u5b66\u6027\u8d28\uff0c\u6bd4\u5982\u9ad8\u65af\u5206\u5e03\u5728\u4eff\u5c04\u53d8\u6362\u540e\u4f9d\u7136\u662f\u9ad8\u65af\u5206\u5e03\uff0c\u800c\u6cbf\u7740\u67d0\u4e2a\u8f74\u79ef\u5206\u5c06\u9ad8\u65af\u5206\u5e03\u4ece 3D \u964d\u5230 2D \u540e\u5176\u4f9d\u7136\u670d\u4ece\u9ad8\u65af\u5206\u5e03\u3002\u9ad8\u65af\u5206\u5e03\u7684\u6570\u5b66\u63cf\u8ff0\u5982\u4e0b\uff1a</p> \\[ \\small G(x;\\mu,\\Sigma) = \\cfrac{1}{\\sqrt{(2\\pi)^k|\\Sigma|}}\\exp\\bigg(-\\frac{1}{2}(x-\\mu)^T\\Sigma^{-1}(x-\\mu)\\bigg)  % = \\cfrac{1}{\\sqrt{(2\\pi)^3|\\Sigma|}}\\exp\\Bigg(-\\frac{1}{2}\\bigg(\\frac{(x-\\mu_1)^2}{\\sigma_1^2}+\\frac{(y-\\mu_2)^2}{\\sigma_2^2}+\\frac{(z-\\mu_3)^2}{\\sigma_3^2}-\\frac{2\\sigma_{xy}(x-\\mu_1)(y-\\mu_2)}{\\sigma_1\\sigma_2}-\\frac{2\\sigma_{xz}(x-\\mu_1)(z-\\mu_3)}{\\sigma_1\\sigma_3}-\\frac{2\\sigma_{yz}(y-\\mu_2)(z-\\mu_3)}{\\sigma_2\\sigma_3}\\bigg)\\Bigg) \\] <p>\u540c\u65f6\uff0c\u4efb\u610f\u692d\u7403\u90fd\u53ef\u4ee5\u7531\u67d0\u4e2a\u692d\u7403\u7ecf\u8fc7\u4eff\u5c04\u53d8\u6362\u5f97\u5230\uff08\u8fd9\u5176\u5b9e\u5bf9\u5e94\u4e8e\u4ece\u4e16\u754c\u5750\u6807\u7cfb\u5230\u76f8\u673a\u5750\u6807\u7cfb\u7684\u89c2\u6d4b\u53d8\u6362\uff0c\u6240\u8c13\u201c\u6a2a\u770b\u6210\u5cad\u4fa7\u6210\u5cf0\uff0c\u8fdc\u8fd1\u9ad8\u4f4e\u5404\u4e0d\u540c\u201d\uff0c\u5728\u8fd9\u91cc\u6307\u7684\u5c31\u662f\u4e0d\u540c\u89c6\u89d2\u4e0b\u770b\u5230\u7684\u692d\u7403\u5f62\u72b6\u662f\u4e0d\u540c\u7684\uff09\uff0c\u800c\u4eff\u5c04\u53d8\u6362\u5de6\u4e58\u7684\u77e9\u9635 \\(\\small W\\) \u53ef\u4ee5\u89c6\u4e3a\u65cb\u8f6c\u548c\u7f29\u653e\u8fd9\u4e24\u4e2a\u4f5c\u7528\u7684\u5408\u6210\uff0c\u5373 \\(\\small W=RS\\)\uff1a</p> \\[ \\small y = Wx+b = RSx+b,\\thinspace\\thinspace x\\sim N(\\mu,\\Sigma) \\thinspace\\thinspace\\thinspace\\thinspace\\thinspace\\Longrightarrow\\thinspace\\thinspace\\thinspace\\thinspace\\thinspace y\\sim N(W\\mu+b, W\\Sigma W^T) = N(W\\mu+b, RS\\Sigma S^TR^T) \\] <p>\u7279\u522b\u5730\uff0c\u5f53 \\(\\small x\\) \u670d\u4ece\u6807\u51c6\u6b63\u6001\u5206\u5e03\u65f6\uff0c\u4eff\u5c04\u53d8\u6362\u5f97\u5230\u7684\u534f\u65b9\u5dee\u77e9\u9635\u4e3a \\(\\small RSS^TR^T\\)\uff1b\u53cd\u8fc7\u6765\uff0c\u7ed9\u5b9a\u534f\u65b9\u5dee\u77e9\u9635 \\(\\small\\Sigma\\)\uff0c\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u7279\u5f81\u5206\u89e3\u5f97\u5230 \\(\\small R\\) \u548c \\(\\small S\\)\uff0c\u5373 \\(\\small\\Sigma=Q\\wedge Q^T=Q\\wedge^{1/2}\\wedge^{1/2} Q^T:=RSS^TR^T\\) (\u7531\u6b64\u53ef\u77e5\u5b58\u50a8\u4e00\u4e2a\u534f\u65b9\u5dee\u77e9\u9635\u9700\u8981\u4e03\u4e2a\u53c2\u6570\uff0c\u5373\u56db\u5143\u6570\u548c\u4e09\u4e2a\u7f29\u653e\u53c2\u6570)\u3002\u4e0b\u9762\u7684 <code>computeCov3D</code> \u51fd\u6570\u5c31\u5728\u8bb2\u8fd9\u4e2a\u4eff\u5c04\u53d8\u6362\uff0c\u4f20\u5165\u7684\u4e09\u7ef4\u5411\u91cf <code>scale</code> \u5373\u4e3a\u4e0a\u8ff0\u516c\u5f0f\u4e2d\u7684 \\(\\small x\\)\uff0c <code>cov3D</code> \u5219\u8868\u793a\u534f\u65b9\u5dee\u77e9\u9635\uff0c\u53ea\u662f\u4f20\u5165\u7684\u56db\u5143\u6570 <code>rot4</code> \u4f7f\u5f97\u4ee3\u7801\u591a\u4e86\u4e00\u4e2a\u8ba1\u7b97\u65cb\u8f6c\u77e9\u9635\u7684\u8fc7\u7a0b\u3002</p> <pre><code>/* submodules/diff-gaussian-rasterization/cuda_rasterizer/forward.cu */\n// Forward method for converting scale and rotation properties of each Gaussian to \n// a 3D covariance matrix in world space. Also takes care of quaternion normalization.\n__device__ void computeCov3D(const glm::vec3 scale, float mod, const glm::vec4 rot, float* cov3D)\n{\n    // Create scaling matrix\n    glm::mat3 S = glm::mat3(1.0f);\n    S[0][0] = mod * scale.x;\n    S[1][1] = mod * scale.y;\n    S[2][2] = mod * scale.z;\n\n    // Normalize quaternion to get valid rotation\n    glm::vec4 q = rot;\n    float r = q.x;\n    float x = q.y;\n    float y = q.z;\n    float z = q.w;\n\n    // Compute rotation matrix from quaternion\n    glm::mat3 R = glm::mat3(\n        1.f - 2.f * (y * y + z * z), 2.f * (x * y - r * z), 2.f * (x * z + r * y),\n        2.f * (x * y + r * z), 1.f - 2.f * (x * x + z * z), 2.f * (y * z - r * x),\n        2.f * (x * z - r * y), 2.f * (y * z + r * x), 1.f - 2.f * (x * x + y * y)\n    );\n\n    glm::mat3 M = S * R;\n\n    // Compute 3D world covariance matrix Sigma\n    glm::mat3 Sigma = glm::transpose(M) * M;\n\n    // Covariance is symmetric, only store upper right\n    cov3D[0] = Sigma[0][0];\n    cov3D[1] = Sigma[0][1];\n    cov3D[2] = Sigma[0][2];\n    cov3D[3] = Sigma[1][1];\n    cov3D[4] = Sigma[1][2];\n    cov3D[5] = Sigma[2][2];\n}\n</code></pre>"},{"location":"src/RL/gaussian-splatting/gaussian-splatting/#\u629b\u96ea\u7403\u5c06\u4e09\u7ef4\u692d\u7403\u6295\u5f71\u5230\u4e8c\u7ef4","title":"\u629b\u96ea\u7403\uff1a\u5c06\u4e09\u7ef4\u692d\u7403\u6295\u5f71\u5230\u4e8c\u7ef4","text":"<p>\u4ece\u4e16\u754c\u5750\u6807\u7cfb\u5230\u76f8\u673a\u5750\u6807\u7cfb\u7684\u89c2\u6d4b\u53d8\u6362\u901a\u8fc7\u4e0a\u9762\u7684\u4eff\u5c04\u53d8\u6362\u63cf\u8ff0\uff0c\u800c\u76f8\u673a\u5750\u6807\u7cfb\u5230\u5f52\u4e00\u5316\u5750\u6807\u7cfb\u7684\u6295\u5f71\u53d8\u6362\u5374\u5e76\u4e0d\u662f\u4e00\u4e2a\u7ebf\u6027\u53d8\u6362\uff0c\u5b83\u9700\u8981\u5c06\u89c6\u9525\u7684\u5c41\u80a1\u538b\u6241\u5e76\u538b\u6210\u6b63\u65b9\u4f53\uff08\u8fd9\u6837\u4e00\u6765\u4e5f\u5c06\u5c04\u7ebf\u4e0e\u5750\u6807\u8f74\u5e73\u884c\u5bf9\u9f50\uff0c\u4f7f\u5f97\u6cbf\u5c04\u7ebf\u7684\u79ef\u5206\u8ba1\u7b97\u53d8\u5f97\u66f4\u52a0\u65b9\u4fbf\uff09\uff0c\u6240\u4ee5\u6211\u4eec\u8003\u8651\u5f15\u5165\u96c5\u53ef\u6bd4\u77e9\u9635\u5bf9\u8be5\u975e\u7ebf\u6027\u53d8\u6362\u4f5c\u5c40\u90e8\u7ebf\u6027\u8fd1\u4f3c\uff0c\u4e5f\u5c31\u662f\u7528\u4eff\u5c04\u53d8\u6362\u6765\u8fd1\u4f3c\u5c40\u90e8\u7684\u6295\u5f71\u4f5c\u7528\u3002\u90a3\u4e48\uff0c\u5728\u8be5\u538b\u6241\u7684\u5c04\u7ebf\u5750\u6807\u7cfb\u4e0b\u7684\u534f\u65b9\u5dee\u77e9\u9635\u4e3a \\(\\small\\Sigma_{ray}=JW\\Sigma W^TJ^T\\)\uff0c\u800c\u5747\u503c\u672c\u8eab\u4fbf\u662f\u9ad8\u65af\u692d\u7403\u7684\u4e2d\u5fc3\u70b9\uff0c\u53ef\u76f4\u63a5\u5bf9\u5176\u5e94\u7528\u6295\u5f71\u53d8\u6362\u3002\u5982\u6b64\uff0c\u518d\u5bf9\u6295\u5f71\u540e\u7684\u9ad8\u65af\u692d\u5706\u4f5c\u89c6\u53e3\u53d8\u6362\u4fbf\u53ef\u5f97\u5230\u5176\u5728\u50cf\u7d20\u5750\u6807\u7cfb\u4e0b\u7684\u8868\u793a\u3002</p> <p></p> <p>\u6b63\u56e0\u4e3a\u662f\u5c40\u90e8\u7ebf\u6027\u8fd1\u4f3c\uff0c\u6240\u4ee5\u4e0b\u9762\u6295\u5f71\u53d8\u6362\u7684 <code>computeCov2D</code> \u51fd\u6570\u9700\u8981\u5148\u8ba1\u7b97\u9ad8\u65af\u692d\u7403\u5747\u503c\u70b9\u5728\u89c6\u9525\u4e2d\u7684\u4f4d\u7f6e\uff1b\u4e5f\u6b63\u56e0\u4e3a\u89c6\u9525\u538b\u6241\u540e\u7684\u6b63\u4ea4\u6295\u5f71\u4e0e \\(\\small z\\) \u65b9\u5411\u65e0\u5173\uff0c\u6240\u4ee5\u5b9e\u9645\u4e0a\u96c5\u53ef\u6bd4\u77e9\u9635\u7684\u7b2c\u4e09\u884c\u662f\u53ef\u4ee5\u7f6e\u96f6\u7684\u3002</p> <pre><code>/* submodules/diff-gaussian-rasterization/cuda_rasterizer/forward.cu */\n// Forward version of 2D covariance matrix computation\n__device__ float3 computeCov2D(const float3&amp; mean, float focal_x, float focal_y, float tan_fovx, float tan_fovy, const float* cov3D, const float* viewmatrix)\n{\n\t// The following models the steps outlined by equations 29 and 31 in \"EWA Splatting\" (Zwicker et al., 2002). \n\t// Additionally considers aspect / scaling of viewport.\n\t// Transposes used to account for row-/column-major conventions.\n\tfloat3 t = transformPoint4x3(mean, viewmatrix);\n\n\tconst float limx = 1.3f * tan_fovx;\n\tconst float limy = 1.3f * tan_fovy;\n\tconst float txtz = t.x / t.z;\n\tconst float tytz = t.y / t.z;\n\tt.x = min(limx, max(-limx, txtz)) * t.z;\n\tt.y = min(limy, max(-limy, tytz)) * t.z;\n\n\tglm::mat3 J = glm::mat3(\n\t\tfocal_x / t.z, 0.0f, -(focal_x * t.x) / (t.z * t.z),\n\t\t0.0f, focal_y / t.z, -(focal_y * t.y) / (t.z * t.z),\n\t\t0, 0, 0);\n\n\tglm::mat3 W = glm::mat3(\n\t\tviewmatrix[0], viewmatrix[4], viewmatrix[8],\n\t\tviewmatrix[1], viewmatrix[5], viewmatrix[9],\n\t\tviewmatrix[2], viewmatrix[6], viewmatrix[10]);\n\n\tglm::mat3 T = W * J;\n\n\tglm::mat3 Vrk = glm::mat3(\n\t\tcov3D[0], cov3D[1], cov3D[2],\n\t\tcov3D[1], cov3D[3], cov3D[4],\n\t\tcov3D[2], cov3D[4], cov3D[5]);\n\n\tglm::mat3 cov = glm::transpose(T) * glm::transpose(Vrk) * T;\n\n\treturn { float(cov[0][0]), float(cov[0][1]), float(cov[1][1]) };\n}\n</code></pre>"},{"location":"src/RL/gaussian-splatting/gaussian-splatting/#\u96ea\u7403\u989c\u8272\u548c\u50cf\u7d20\u7740\u8272\u7403\u8c10\u51fd\u6570","title":"\u96ea\u7403\u989c\u8272\u548c\u50cf\u7d20\u7740\u8272\uff1a\u7403\u8c10\u51fd\u6570","text":"<p>\u901a\u8fc7\u4e0a\u8ff0\u8fc7\u7a0b\uff0c\u6211\u4eec\u5df2\u7ecf\u634f\u597d\u4e86\u96ea\u7403\uff0c\u4e5f\u60f3\u597d\u5982\u4f55\u628a\u96ea\u7403\u5f80\u5899\u4e0a\u7838\u4e86\uff0c\u4f46\u96ea\u7403\u4e0d\u4e00\u5b9a\u662f\u767d\u8272\u7684 \u2014\u2014 3DGS \u5229\u7528\u7403\u8c10\u51fd\u6570 \\(\\small\\sum_l\\sum_{m=-l}^l c_l^my_l^m(\\theta,\\phi)\\) \u6765\u8868\u8fbe\u9ad8\u65af\u692d\u7403\u7684\u989c\u8272\u3002\u76f8\u6bd4 RGB \u4fe1\u606f\uff08\u5bf9\u5e94\u4e8e\u96f6\u9636\u7403\u8c10\u51fd\u6570\uff09\uff0c\u9ad8\u9636\u7403\u8c10\u51fd\u6570\u7ed9\u51fa\u4e86\u66f4\u4e3a\u903c\u771f\u7684\u73af\u5883\u8d34\u56fe\u548c\u4eae\u5ea6\u91cd\u5efa\u6548\u679c\uff0c\u4f7f\u5f97\u692d\u7403\u5448\u73b0\u7684\u989c\u8272\u4e0e\u89c2\u6d4b\u65b9\u5411\u76f8\u5173 \u2014\u2014 \u76f4\u89c9\u4e0a\u8bb2\u7403\u8c10\u51fd\u6570\u5305\u542b\u4e86\u66f4\u4e3a\u4e30\u5bcc\u7684\u4fe1\u606f\uff0c\u6bd4\u5982\u4e09\u9636\u7403\u8c10\u51fd\u6570\u6240\u5305\u542b\u7684\u4fe1\u606f\u91cf\u8fbe\u5230\u4e86 \\(\\small (1+3+5+7)\\times 3\\)\u3002\u4e0b\u9762\u4ee3\u7801\u4f20\u5165\u7684\u53c2\u6570 <code>deg</code> \u5373\u4e3a\u7403\u8c10\u51fd\u6570\u7684\u9636\u6570\uff0c<code>glm::vec3 result = SH_C0 * sh[0]</code> \u4fbf\u662f\u5728\u7b97\u7b2c\u96f6\u9636\u7684\u5143\u7d20\uff0c\u540e\u7eed\u5219\u6309\u516c\u5f0f\u5206\u522b\u8ba1\u7b97\u4e0d\u540c\u9636\u6b21\u7684\u7403\u8c10\u51fd\u6570\u503c\u3002</p> <pre><code>/* submodules/diff-gaussian-rasterization/cuda_rasterizer/forward.cu */\n// Forward method for converting the input spherical harmonics coefficients of each Gaussian to a simple RGB color.\n__device__ glm::vec3 computeColorFromSH(int idx, int deg, int max_coeffs, const glm::vec3* means, glm::vec3 campos, const float* shs, bool* clamped)\n{\n\t// The implementation is loosely based on code for \n\t// \"Differentiable Point-Based Radiance Fields for \n\t// Efficient View Synthesis\" by Zhang et al. (2022)\n\tglm::vec3 pos = means[idx];\n\tglm::vec3 dir = pos - campos;\n\tdir = dir / glm::length(dir);\n\n\tglm::vec3* sh = ((glm::vec3*)shs) + idx * max_coeffs;\n\tglm::vec3 result = SH_C0 * sh[0];\n\n\tif (deg &gt; 0)\n\t{\n\t\tfloat x = dir.x;\n\t\tfloat y = dir.y;\n\t\tfloat z = dir.z;\n\t\tresult = result - SH_C1 * y * sh[1] + SH_C1 * z * sh[2] - SH_C1 * x * sh[3];\n\n\t\tif (deg &gt; 1)\n\t\t{\n\t\t\tfloat xx = x * x, yy = y * y, zz = z * z;\n\t\t\tfloat xy = x * y, yz = y * z, xz = x * z;\n\t\t\tresult = result +\n\t\t\t\tSH_C2[0] * xy * sh[4] +\n\t\t\t\tSH_C2[1] * yz * sh[5] +\n\t\t\t\tSH_C2[2] * (2.0f * zz - xx - yy) * sh[6] +\n\t\t\t\tSH_C2[3] * xz * sh[7] +\n\t\t\t\tSH_C2[4] * (xx - yy) * sh[8];\n\n\t\t\tif (deg &gt; 2)\n\t\t\t{\n\t\t\t\tresult = result +\n\t\t\t\t\tSH_C3[0] * y * (3.0f * xx - yy) * sh[9] +\n\t\t\t\t\tSH_C3[1] * xy * z * sh[10] +\n\t\t\t\t\tSH_C3[2] * y * (4.0f * zz - xx - yy) * sh[11] +\n\t\t\t\t\tSH_C3[3] * z * (2.0f * zz - 3.0f * xx - 3.0f * yy) * sh[12] +\n\t\t\t\t\tSH_C3[4] * x * (4.0f * zz - xx - yy) * sh[13] +\n\t\t\t\t\tSH_C3[5] * z * (xx - yy) * sh[14] +\n\t\t\t\t\tSH_C3[6] * x * (xx - 3.0f * yy) * sh[15];\n\t\t\t}\n\t\t}\n\t}\n\tresult += 0.5f;\n\n\t// RGB colors are clamped to positive values. If values are\n\t// clamped, we need to keep track of this for the backward pass.\n\tclamped[3 * idx + 0] = (result.x &lt; 0);\n\tclamped[3 * idx + 1] = (result.y &lt; 0);\n\tclamped[3 * idx + 2] = (result.z &lt; 0);\n\treturn glm::max(result, 0.0f);\n}\n</code></pre> <p>\\(\\small\\alpha-blending\\) \u4e2d\u7684\u50cf\u7d20\u989c\u8272\u662f\u901a\u8fc7\u6cbf\u5c04\u7ebf\u7684\u4f53\u6e32\u67d3\u5f97\u5230\u7684\uff0c\u5373\u5c06\u9ad8\u65af\u692d\u7403\u6309\u7167\u5c04\u7ebf\u5750\u6807\u7cfb\u7684\u6df1\u5ea6\u6392\u5e8f\uff0c\u7136\u540e\u6309\u4ece\u8fd1\u5230\u8fdc\u7684\u987a\u5e8f\u4f9d\u6b21\u629b\u51fa\uff1a\\(\\small C=\\sum_{i=1}^N T_i\\alpha_ic_i=\\sum_{i=1}^N\\prod_{j=1}^{i-1}(1-\\alpha_i)\\big(1-\\exp(-\\sigma_i\\delta_i)\\big)c_i\\)\uff0c\u5176\u4e2d \\(\\small T(s)\\) \u8868\u793a\u5728 \\(\\small s\\) \u70b9\u4e4b\u524d\u5149\u7ebf\u6ca1\u6709\u88ab\u963b\u788d\u7684\u6982\u7387\u6216\u8005\u8bf4\u900f\u8fc7\u7387\uff0c\\(\\small\\sigma(s)\\) \u8868\u793a\u5728 \\(\\small s\\) \u70b9\u5904\u5149\u7ebf\u649e\u51fb\u7c92\u5b50\u6216\u8005\u8bf4\u88ab\u7c92\u5b50\u963b\u788d\u7684\u6982\u7387\uff0c\\(\\small c(s)\\) \u8868\u793a\u5728 \\(\\small s\\) \u70b9\u5904\u7c92\u5b50\u53d1\u51fa\u7684\u989c\u8272\uff0c\\(\\small\\delta(s)\\) \u5219\u8868\u793a\u70b9 \\(\\small s\\) \u5904\u6cbf\u5c04\u7ebf\u79bb\u6563\u79ef\u5206\u7684\u95f4\u8ddd\u3002\u4e0b\u9762\u4ee3\u7801\u7684\u9ad8\u4eae\u90e8\u5206\u5bf9\u5e94\u7684\u5c31\u662f\u4e0a\u8ff0\u516c\u5f0f\u3002</p> <pre><code>/* submodules/diff-gaussian-rasterization/cuda_rasterizer/forward.cu */\n// Main rasterization method. Collaboratively works on one tile per block, \n// each thread treats one pixel. Alternates between fetching and rasterizing data.\ntemplate &lt;uint32_t CHANNELS&gt;\n__global__ void __launch_bounds__(BLOCK_X * BLOCK_Y)\nrenderCUDA(\n\tconst uint2* __restrict__ ranges,\n\tconst uint32_t* __restrict__ point_list,\n\tint W, int H,\n\tconst float2* __restrict__ points_xy_image,\n\tconst float* __restrict__ features,\n\tconst float4* __restrict__ conic_opacity,\n\tfloat* __restrict__ final_T,\n\tuint32_t* __restrict__ n_contrib,\n\tconst float* __restrict__ bg_color,\n\tfloat* __restrict__ out_color,\n\tconst float* __restrict__ depths,\n\tfloat* __restrict__ invdepth)\n{\n\t// Identify current tile and associated min/max pixel range.\n\tauto block = cg::this_thread_block();\n\tuint32_t horizontal_blocks = (W + BLOCK_X - 1) / BLOCK_X;\n\tuint2 pix_min = { block.group_index().x * BLOCK_X, block.group_index().y * BLOCK_Y };\n\tuint2 pix_max = { min(pix_min.x + BLOCK_X, W), min(pix_min.y + BLOCK_Y , H) };\n\tuint2 pix = { pix_min.x + block.thread_index().x, pix_min.y + block.thread_index().y };\n\tuint32_t pix_id = W * pix.y + pix.x;\n\tfloat2 pixf = { (float)pix.x, (float)pix.y };\n\n\t// Check if this thread is associated with a valid pixel or outside.\n\tbool inside = pix.x &lt; W&amp;&amp; pix.y &lt; H;\n\t// Done threads can help with fetching, but don't rasterize\n\tbool done = !inside;\n\n\t// Load start/end range of IDs to process in bit sorted list.\n\tuint2 range = ranges[block.group_index().y * horizontal_blocks + block.group_index().x];\n\tconst int rounds = ((range.y - range.x + BLOCK_SIZE - 1) / BLOCK_SIZE);\n\tint toDo = range.y - range.x;\n\n\t// Allocate storage for batches of collectively fetched data.\n\t__shared__ int collected_id[BLOCK_SIZE];\n\t__shared__ float2 collected_xy[BLOCK_SIZE];\n\t__shared__ float4 collected_conic_opacity[BLOCK_SIZE];\n\n\t// Initialize helper variables\n\tfloat T = 1.0f;\n\tuint32_t contributor = 0;\n\tuint32_t last_contributor = 0;\n\tfloat C[CHANNELS] = { 0 };\n\n\tfloat expected_invdepth = 0.0f;\n\n\t// Iterate over batches until all done or range is complete\n\tfor (int i = 0; i &lt; rounds; i++, toDo -= BLOCK_SIZE)\n\t{\n\t\t// End if entire block votes that it is done rasterizing\n\t\tint num_done = __syncthreads_count(done);\n\t\tif (num_done == BLOCK_SIZE)\n\t\t\tbreak;\n\n\t\t// Collectively fetch per-Gaussian data from global to shared\n\t\tint progress = i * BLOCK_SIZE + block.thread_rank();\n\t\tif (range.x + progress &lt; range.y)\n\t\t{\n\t\t\tint coll_id = point_list[range.x + progress];\n\t\t\tcollected_id[block.thread_rank()] = coll_id;\n\t\t\tcollected_xy[block.thread_rank()] = points_xy_image[coll_id];\n\t\t\tcollected_conic_opacity[block.thread_rank()] = conic_opacity[coll_id];\n\t\t}\n\t\tblock.sync();\n\n\t\t// Iterate over current batch\n\t\tfor (int j = 0; !done &amp;&amp; j &lt; min(BLOCK_SIZE, toDo); j++)\n\t\t{\n\t\t\t// Keep track of current position in range\n\t\t\tcontributor++;\n\n\t\t\t// Resample using conic matrix (cf. \"Surface \n\t\t\t// Splatting\" by Zwicker et al., 2001)\n\t\t\tfloat2 xy = collected_xy[j];\n\t\t\tfloat2 d = { xy.x - pixf.x, xy.y - pixf.y };\n\t\t\tfloat4 con_o = collected_conic_opacity[j];\n\t\t\tfloat power = -0.5f * (con_o.x * d.x * d.x + con_o.z * d.y * d.y) - con_o.y * d.x * d.y;\n\t\t\tif (power &gt; 0.0f)\n\t\t\t\tcontinue;\n\n\t\t\t// Eq. (2) from 3D Gaussian splatting paper.\n\t\t\t// Obtain alpha by multiplying with Gaussian opacity\n\t\t\t// and its exponential falloff from mean.\n\t\t\t// Avoid numerical instabilities (see paper appendix). \n\t\t\tfloat alpha = min(0.99f, con_o.w * exp(power));\n\t\t\tif (alpha &lt; 1.0f / 255.0f)\n\t\t\t\tcontinue;\n\t\t\tfloat test_T = T * (1 - alpha);\n\t\t\tif (test_T &lt; 0.0001f)\n\t\t\t{\n\t\t\t\tdone = true;\n\t\t\t\tcontinue;\n\t\t\t}\n\n\t\t\t// Eq. (3) from 3D Gaussian splatting paper.\n\t\t\tfor (int ch = 0; ch &lt; CHANNELS; ch++)\n\t\t\t\tC[ch] += features[collected_id[j] * CHANNELS + ch] * alpha * T;\n\n\t\t\tif(invdepth)\n\t\t\texpected_invdepth += (1 / depths[collected_id[j]]) * alpha * T;\n\n\t\t\tT = test_T;\n\n\t\t\t// Keep track of last range entry to update this\n\t\t\t// pixel.\n\t\t\tlast_contributor = contributor;\n\t\t}\n\t}\n\n\t// All threads that treat valid pixel write out their final\n\t// rendering data to the frame and auxiliary buffers.\n\tif (inside)\n\t{\n\t\tfinal_T[pix_id] = T;\n\t\tn_contrib[pix_id] = last_contributor;\n\t\tfor (int ch = 0; ch &lt; CHANNELS; ch++)\n\t\t\tout_color[ch * H * W + pix_id] = C[ch] + T * bg_color[ch];\n\n\t\tif (invdepth)\n\t\tinvdepth[pix_id] = expected_invdepth;// 1. / (expected_depth + T * 1e3);\n\t}\n}\n</code></pre>"},{"location":"src/RL/gaussian-splatting/gaussian-splatting/#\u5b8c\u6574\u6d41\u7a0b\u673a\u5668\u5b66\u4e60\u4e0e\u53c2\u6570\u8bc4\u4f30","title":"\u5b8c\u6574\u6d41\u7a0b\uff1a\u673a\u5668\u5b66\u4e60\u4e0e\u53c2\u6570\u8bc4\u4f30","text":"<p>\u6bcf\u4e2a\u70b9\u81a8\u80c0\u6210\u7684\u4e09\u7ef4\u9ad8\u65af\u692d\u7403\u53c2\u6570\u5305\u62ec\u4e2d\u5fc3\u70b9\u4f4d\u7f6e \\(\\small (x,y,z)\\)\u3001\u534f\u65b9\u5dee\u77e9\u9635 \\(\\small\\Sigma=RS\\)\u3001\u7403\u8c10\u51fd\u6570\u7cfb\u6570\u77e9\u9635\u548c\u900f\u660e\u5ea6 \\(\\small\\alpha\\)\uff0c\u8fd9\u4e9b\u521d\u59cb\u5316\u7684\u9ad8\u65af\u692d\u7403\u901a\u8fc7\u4e0a\u8ff0\u6cfc\u6e85\u7684\u8fc7\u7a0b\u5f97\u5230\u4e8c\u7ef4\u56fe\u50cf\uff0c\u518d\u5c06\u8be5\u56fe\u50cf\u548c Ground Truth \u7684\u8bef\u5dee\u53cd\u5411\u4f20\u64ad\u6765\u4f18\u5316\u692d\u7403\u53c2\u6570\uff0c\u5176\u4e2d\u635f\u5931\u51fd\u6570\u88ab\u5b9a\u4e49\u4e3a \\(\\small\\mathcal{L}=(1-\\lambda)\\mathcal{L}_1 + \\lambda\\mathcal{L}_{D-SSIM}\\)\uff0c\u5982\u4e0b\u8ff0\u4ee3\u7801\u5757\u6240\u793a\uff08\u53ef\u4ee5\u6ce8\u610f\u5230\u4ee3\u7801\u4e2d\u8fd8\u8ba1\u7b97\u4e86\u6df1\u5ea6\u6b63\u5219\u5316\u635f\u5931\u6765\u5f15\u5bfc\u9ad8\u65af\u692d\u7403\u7684\u51e0\u4f55\u5206\u5e03\u4e0e\u5355\u76ee\u5148\u9a8c\u6df1\u5ea6\u4f30\u8ba1\u4fdd\u6301\u4e00\u81f4\uff0c\u800c\u91c7\u7528\u9006\u6df1\u5ea6\u56fe\u5219\u662f\u56e0\u4e3a\u8fd1\u5904\u7684\u6df1\u5ea6\u4f30\u8ba1\u66f4\u4e3a\u51c6\u786e\uff09\u3002\u53ef\u4ee5\u6ce8\u610f\u5230\u7684\u662f\uff0c\u4ee3\u7801 <code>submodules</code> \u6a21\u5757\u4e0b\u6709 <code>simple-knn</code> \u90e8\u5206\uff0c\u8fd9\u662f\u56e0\u4e3a\u9ad8\u65af\u692d\u7403\u88ab\u521d\u59cb\u5316\u4e3a\u4e00\u4e2a\u5404\u5411\u540c\u6027\u7684\u7403\uff0c\u5176\u534a\u5f84\u88ab\u8bbe\u4e3a\u4e09\u8fd1\u90bb\u8ddd\u79bb\u7684\u5e73\u5747\u503c\u4ee5\u907f\u514d\u692d\u7403\u94fa\u4e0d\u6ee1\u573a\u666f\u6216\u8005\u8fc7\u5ea6\u91cd\u53e0\u7684\u60c5\u51b5\u3002</p> <pre><code>''' train.py '''\ndef training(dataset, opt, pipe, testing_iterations, saving_iterations, checkpoint_iterations, checkpoint, debug_from):\n\t...\n\t# Loss\n\tgt_image = viewpoint_cam.original_image.cuda()\n\tLl1 = l1_loss(image, gt_image)\n\tif FUSED_SSIM_AVAILABLE:\n\t\tssim_value = fused_ssim(image.unsqueeze(0), gt_image.unsqueeze(0))\n\telse:\n\t\tssim_value = ssim(image, gt_image)\n\n\tloss = (1.0 - opt.lambda_dssim) * Ll1 + opt.lambda_dssim * (1.0 - ssim_value)\n\n\t# Depth regularization\n\tLl1depth_pure = 0.0\n\tif depth_l1_weight(iteration) &gt; 0 and viewpoint_cam.depth_reliable:\n\t\tinvDepth = render_pkg[\"depth\"]\n\t\tmono_invdepth = viewpoint_cam.invdepthmap.cuda()\n\t\tdepth_mask = viewpoint_cam.depth_mask.cuda()\n\n\t\tLl1depth_pure = torch.abs((invDepth  - mono_invdepth) * depth_mask).mean()\n\t\tLl1depth = depth_l1_weight(iteration) * Ll1depth_pure\n\t\tloss += Ll1depth\n\t\tLl1depth = Ll1depth.item()\n\telse:\n\t\tLl1depth = 0\n\n\tloss.backward()\n</code></pre> <p>\u4f46\u662f\u5982\u679c\u53ea\u5bf9 colmap \u751f\u6210\u7684\u521d\u59cb\u70b9\u4e91\u4f5c\u4f18\u5316\u7684\u8bdd\uff0c\u90a3\u4e48\u540e\u7eed\u4e0d\u7ba1\u5982\u4f55\u4f18\u5316\u9ad8\u65af\u692d\u7403\u7684\u6570\u91cf\u90fd\u662f\u4e0d\u53d8\u7684\uff0c\u8fd9\u4f7f\u5f97\u7b97\u6cd5\u5f3a\u4f9d\u8d56\u4e8e SfM \u7684\u521d\u59cb\u5316\uff0c\u6240\u4ee5 3DGS \u63d0\u51fa\u4e86\u81ea\u9002\u5e94\u5bc6\u5ea6\u63a7\u5236\u4e0e\u4f18\u5316\uff0c\u5373\u5bf9\u900f\u660e\u7684\u9ad8\u65af\u5206\u5e03\u4f5c\u5468\u671f\u6027\u6ee4\u9664\u6216\u8005\u8bf4\u5254\u9664\u5b58\u5728\u611f\u592a\u4f4e\u7684\u9ad8\u65af\u692d\u7403\uff0c\u540c\u65f6\uff0c\u5bf9\u4e8e under-reconstruction \u7684\u533a\u57df\uff0c\u514b\u9686\u9ad8\u65af\u5e76\u6cbf\u7740\u68af\u5ea6\u65b9\u5411\u79fb\u52a8\u4ee5\u8986\u76d6\u51e0\u4f55\u4f53\uff1b\u5bf9\u4e8e over-reconstruction \u7684\u533a\u57df\u5219\u62c6\u5206\u9ad8\u65af\u4ee5\u66f4\u597d\u5730\u62df\u5408\u7ec6\u7c92\u5ea6\u7ec6\u8282\u3002\u53ef\u4ee5\u53d1\u73b0\uff0c\u673a\u5668\u5b66\u4e60\u7684\u90e8\u5206\u975e\u5e38\u7b80\u5355\u4e14\u4e0d\u6d89\u53ca\u6df1\u5ea6\u5b66\u4e60\u7684\u77e5\u8bc6\uff0c3DGS \u7684\u96be\u5ea6\u4e3b\u8981\u5728\u4e8e\u5bf9\u8ba1\u7b97\u673a\u56fe\u5f62\u5b66\u7684\u7406\u89e3\u548c GPU \u7684\u9ad8\u6027\u80fd\u7f16\u7a0b\u30023DGS \u8fd9\u90e8\u5206\u7684\u4f2a\u4ee3\u7801\u89c1\u8bba\u6587\u7684\u9644\u5f55 B. Optimization and Densification Algorithm\u3002</p> <p></p> <p>\u6ce8\uff1a\u7f51\u4e0a\u6709\u53cd\u6620\u8bf4\u539f\u7248 3DGS \u5185\u7f6e\u7684\u67e5\u770b\u5668\u4e0d\u592a\u597d\u7528\uff0c\u53ef\u4ee5\u8003\u8651\u6362\u7528 gaussian-splatting-lightning\u3002</p> <p> </p> <p>[1] Kerbl B, Kopanas G, Leimk\u00fchler T, et al. 3D Gaussian splatting for real-time radiance field rendering[J]. ACM Trans. Graph., 2023, 42(4): 139:1-139:14.</p> <p>[2] Bilibili \u4e0a\u7684\u8fd9\u4e2a\u89c6\u9891\u7ed9\u51fa\u4e86 3DGS \u4eba\u6027\u5316\u7684\u8bb2\u89e3\uff0c\u4e5f\u662f\u6211\u8fd9\u7bc7\u7b14\u8bb0\u7684\u6765\u6e90\u3002</p>"}]}